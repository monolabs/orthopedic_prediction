---
title: "Orthopedic Condition Prediction"
author: "Steven Pramono"
date: "12/19/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Datasets

## 1.1. Project Overview

This project aims to analyze biomechanical features of orthopedic patients and use them to predict patients' conditions.
Two datasets were analyzed in this project: "column_2C_weka.csv" and "column_3C_weka.csv". The first classifies diagnostic outcomes into two categories: "Abnormal" and "Normal" while the second further divides abnormality into "Disk Hernia" and "Spondylolisthesis". The datasets are otherwise identical in structure. Both data sets will be referred to in this report as **Data 1** and **Data 2** respectively.

Note: bin_class column is added where "Abnormal" is represented by 0 and "Normal" by 1.

```{r setting up datasets, message=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(Matrix)) install.packages("Matrix", repos = "http://cran.us.r-project.org")

col_names=c("pelvic_incidence","pelvic_tilt","lumbar_lordosis_angle","sacral_slope","pelvic_radius","degree_spondylolisthesis","class")
dat1<-read_csv("../data/column_2C_weka.csv")%>%setNames(col_names)%>%na.omit%>% mutate(class=factor(class,levels=unique(class)))
dat2<-read_csv("../data/column_3C_weka.csv")%>%setNames(col_names)%>%na.omit%>%mutate(class=factor(class,levels=unique(class)))
  
```

We start with **Data 1**, here is the first few lines of the data:

```{r data viewing}
head(dat1)
```

## 1.2. Exploring datasets

### Visualizing the data

We start by simply plotting the distribution of each variables in dat1:

```{r variability of each predictors}
dat1%>%gather(type,value,-class)%>%
  ggplot(aes(type,value,color=class))+
    geom_jitter(alpha=0.2)+
    theme(axis.text.x=element_text(angle=45,hjust=1))
```

There is a clear outlier at degree_spondylolisthesis >400 possibly due to error. Therefore, we exclude that particular observation from analysis:

```{r outlier removal, echo=FALSE}
dat1<-dat1%>%filter(degree_spondylolisthesis<400)
dat1%>%gather(type,value,-class)%>%
  ggplot(aes(type,value,color=class))+
    geom_jitter(alpha=0.2)+
    theme(axis.text.x=element_text(angle=45,hjust=1))
```

Spondylolisthesis degree seems to have the highest predictive power: abnormality is expected from high degree. With histograms, it is easier to analyze the type of distributions each of the predictors has:

```{r predictors histograms, fig.width=12, fig.height=4}
dat1%>%gather(type,value,-class)%>%
  ggplot(aes(value))+
    geom_histogram(binwidth=5)+
    facet_grid(.~type)
```

We can see that distributions of degree_spondylolisthesis is the only one not well approximated by normal distribution.

## 1.3. Data structure

### Correlation

Correlation matrix can be constructed to observe dependencies between predictors:

```{r correlation}
cor1<-cor(dat1[1:(length(dat1)-1)])
cor1
corrplot(cor1)
```

The high correlations between predictors is obvious. Here are some of the plots:

```{r correlation plots, fig.width=12, fig.height=4}
cor_plot_1<-dat1%>%
  ggplot(aes(sacral_slope,pelvic_incidence))+
    geom_point(alpha=0.4)
cor_plot_2<-dat1%>%
  ggplot(aes(lumbar_lordosis_angle,pelvic_incidence))+
    geom_point(alpha=0.4)
cor_plot_3<-dat1%>%
  ggplot(aes(lumbar_lordosis_angle,degree_spondylolisthesis))+
    geom_point(alpha=0.4)
grid.arrange(cor_plot_1,cor_plot_2,cor_plot_3,nrow=1)
```

And if ranks are used instead of the actual values:

```{r correlation plots with ranks, fig.width=12, fig.height=4, echo=FALSE}
cor_plot_1<-dat1%>%
  ggplot(aes(rank(sacral_slope),rank(pelvic_incidence)))+
    geom_point(alpha=0.4)
cor_plot_2<-dat1%>%
  ggplot(aes(rank(lumbar_lordosis_angle),rank(pelvic_incidence)))+
    geom_point(alpha=0.4)
cor_plot_3<-dat1%>%
  ggplot(aes(rank(lumbar_lordosis_angle),rank(degree_spondylolisthesis)))+
    geom_point(alpha=0.4)
grid.arrange(cor_plot_1,cor_plot_2,cor_plot_3,nrow=1)
```


# 2. Machine Learning and Predictive Analysis

In this section, several fitting models were explored and compared. Here is the list of algorithms discussed:

LIST

Evaluation was done using different metrics such as accuracy, precision, F1 score (collectively referred to as **results**). Tuning parameters are optimized whenever applicable. Result from optimized model in each method applied to a test set is documented in a table.

RMSE function is defined...

Default bootstrap samples proportions and numbers of bootstrap sets are used.Test set is comprised of 20% observations, randomly selected using Monte Carlo simulation:

```{r include=FALSE}
set.seed(2346,sample.kind="Rounding")
```
```{r partitioning for Data 1}
test_index1<-createDataPartition(dat1$class,times=1,p=0.2)
test_set1<-dat1[unlist(test_index1),]
train_set1<-dat1[-unlist(test_index1),]
```
```{r include=FALSE}
set.seed(2346,sample.kind="Rounding")
```
```{r partitioning for Data 2}
test_index2<-createDataPartition(dat2$class,times=1,p=0.2)
test_set2<-dat2[unlist(test_index2),]
train_set2<-dat2[-unlist(test_index2),]
```

and prevalence in **train_set1** and **train_set2** respectively:

```{r prevalence in train_sets}
train_set1%>%group_by(class)%>%summarize(n=n())
train_set2%>%group_by(class)%>%summarize(n=n())
```

General function to return accuracies, precision, recall and F1 score are defined with "Abnormal" or "0" as the positive. In this case, it is important to maximize recall to catch as much abnormality as possible.

```{r evaluation functions}
results_func<-function(predictions,tests){ #predictions and tests are both vectors
  cf<-confusionMatrix(data=predictions,reference=tests)
  c(cf$overall['Accuracy'],cf$byClass['Sensitivity'],cf$byClass['Precision'],cf$byClass['F1'])
  }
```


## 2.1. Logistic Regression

Logistic regression is commonly used when the outcome is binary. To train a model using all predictors, we can use the following code:

```{r glm prediction}
fit_glm<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="glm",data=train_set1,family="binomial")
predictions_glm<-predict(fit_glm,newdata=test_set1,type="raw")
results_glm<-results_func(predictions_glm,test_set1$class)
```

We see an error stating probabilities of 0 and 1 are observed in the model fit_glm. Viewing the predictions in descending order of probability_0 helps visualizing the problem.

```{r glm prediction by probability}
predict(fit_glm,newdata=test_set1,type="prob")%>%arrange(desc(Abnormal))%>%head
```

Some of the values of probability_0 are 1 or really close to 1 (or close to 0 for probability_1). Earlier we Restablished that degree_spondylolisthesis of >50 seems to result in 100% probability of being abnormal. Therefore, we can exclude the corresponding observations to get rid of the error.

```{r excluding data with degree_spondylolisthesis >50}
fit_glm2<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="glm",data=train_set1%>%filter(degree_spondylolisthesis<=50),family="binomial")
predictions_glm2<-predict(fit_glm2,newdata=test_set1,type="raw")
results_glm2<-results_func(predictions_glm2,test_set1$class)
```

Note than the resulting model after exclusion seems to give identical prediction.

```{r predictions_glm vs predictions_glm2}
identical(predictions_glm,predictions_glm2)
```

Here is the results:

```{r result_glm, echo=FALSE}
tab_glm<-tibble(data="Data 1",model="glm",accuracy=results_glm2[1],recall=results_glm2[2],precision=results_glm2[3],F1=results_glm2[4])
tab_glm
```


## 2.2. K-Nearest Neighbors (knn)

### Data 1 - Bootstrap

Here we will train knn models for different values of k (tuneLength = 20) and evaluate their performances on the test set. The plot and training results are summarized below.

```{r, include=FALSE}
set.seed(1234,sample.kind="Rounding")
```
```{r knn_bootstrap_Data 1}
fit_knn<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="knn",data=train_set1,tuneLength=20)
predictions_knn<-predict(fit_knn,newdata=test_set1,type="raw")
results_knn<-results_func(predictions_knn,test_set1$class)
fit_knn$results%>%arrange(desc(Accuracy))%>%head
plot(fit_knn)
```

Results for **Data 1** with **knn** and **default bootstrap**:

```{r results_knn_bootstrap_Data 1, echo=FALSE}
tab_knn_boot1<-tibble(data="Data 1",model="knn_bootstrap",accuracy=results_knn[1],recall=results_knn[2],precision=results_knn[3],F1=results_knn[4])
tab_knn_boot1
```

### Data 1 - 10-fold cross validation

```{r, include=FALSE}
set.seed(3573,sample.kind="Rounding")
```
```{r knn_cv_Data 1}
fit_knn_cv1<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="knn",data=train_set1,tuneLength=20,trControl=(trainControl(method="cv",number=10)))
predictions_knn_cv1<-predict(fit_knn_cv1,newdata=test_set1,type="raw")
results_knn_cv1<-results_func(predictions_knn_cv1,test_set1$class)
fit_knn_cv1$results%>%arrange(desc(Accuracy))%>%head
plot(fit_knn_cv1)
```

Results for **Data 1** with **knn** and **10-fold cv**:

```{r results_knn_cv_Data 1, echo=FALSE}
tab_knn_cv1<-tibble(data="Data 1",model="knn_cv",accuracy=results_knn_cv1[1],recall=results_knn_cv1[2],precision=results_knn_cv1[3],F1=results_knn_cv1[4])
tab_knn_cv1
```

### Data 2 - Bootstrap

Knn is supports non-linearity and allows for classification into more than 2 classes. Here is the same procedure done on the second data set with 3 classes of outcome.

```{r, include=FALSE}
set.seed(4365,sample.kind="Rounding")
```
```{r knn_bootstrap_Data 2}
fit_knn2<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="knn",data=train_set1,tuneLength=20)
predictions_knn2<-predict(fit_knn2,newdata=test_set1,type="raw")
results_knn2<-results_func(predictions_knn2,test_set1$class)
fit_knn2$results%>%arrange(desc(Accuracy))%>%head
plot(fit_knn2)
```

Results for **Data 2** with **knn** and **bootstrap**:

```{r result_knn_bootstrap_Data 2, echo=FALSE}
tab_knn_boot2<-tibble(data="Data 2",model="knn_cv",accuracy=results_knn2[1],recall=results_knn2[2],precision=results_knn2[3],F1=results_knn2[4])
tab_knn_boot2
```

```{r, include=FALSE}
set.seed(4589,sample.kind="Rounding")
```
```{r knn_cv_Data 2}
fit_knn_cv2<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="knn",data=train_set1,tuneLength=20,trControl=(trainControl(method="cv",number=10)))
predictions_knn_cv2<-predict(fit_knn_cv2,newdata=test_set1,type="raw")
results_knn_cv2<-results_func(predictions_knn_cv2,test_set1$class)
fit_knn_cv2$results%>%arrange(desc(Accuracy))%>%head
plot(fit_knn_cv2)
```

```{r results_knn_cv_Data 2, echo=FALSE}
tab_knn_cv2<-tibble(data="Data 2",model="knn_cv",accuracy=results_knn_cv2[1],recall=results_knn_cv2[2],precision=results_knn_cv2[3],F1=results_knn_cv2[4])
tab_knn_cv2
```

## Random Forest

### Data 1 - Bootstrap

```{r, include=FALSE}
set.seed(3456,sample.kind="Rounding")
```
```{r rf_bootstrap_Data 1}
fit_rf<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="rf",data=train_set1,tuneLength=5)
predictions_rf<-predict(fit_rf,newdata=test_set1,type="raw")
results_rf<-results_func(predictions_rf,test_set1$class)
fit_rf$results%>%arrange(desc(Accuracy))%>%head
plot(fit_rf)
```

Results for **Data 1** with **rf** and **default bootstrap**:

```{r result_rf_bootstrap_Data 1, echo=FALSE}
tab_rf_boot1<-tibble(data="Data 1",model="rf_bootstrap",accuracy=results_rf[1],recall=results_rf[2],precision=results_rf[3],F1=results_rf[4])
tab_rf_boot1
```

### Data 1 - 10-fold cross validation

```{r, include=FALSE}
set.seed(1296,sample.kind="Rounding")
```
```{r rf_cv_Data 1}
fit_rf_cv1<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="rf",data=train_set1,tuneLength=5,trControl=trainControl(method="cv",number=10))
predictions_rf_cv1<-predict(fit_rf_cv1,newdata=test_set1,type="raw")
results_rf_cv1<-results_func(predictions_rf_cv1,test_set1$class)
fit_rf$results%>%arrange(desc(Accuracy))%>%head
plot(fit_rf_cv1)
```

```{r results_rf_cv_Data 1, echo=FALSE}
tab_rf_cv1<-tibble(data="Data 1",model="rf_cv",accuracy=results_rf_cv1[1],recall=results_rf_cv1[2],precision=results_rf_cv1[3],F1=results_rf_cv1[4])
tab_rf_cv1
```

### Data 2

```{r, include=FALSE}
set.seed(3498,sample.kind="Rounding")
```
```{r rf_bootstrap_Data 2}
fit_rf2<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="rf",data=train_set1,tuneLength=5)
predictions_rf2<-predict(fit_rf2,newdata=test_set1,type="raw")
results_rf2<-results_func(predictions_rf2,test_set1$class)
fit_rf2$results%>%arrange(desc(Accuracy))%>%head
plot(fit_rf2)
```

Results for **Data 2** with **rf** and **default bootstrap**:

```{r result_rf_bootstrap_Data 2, echo=FALSE}
tab_rf_boot2<-tibble(data="Data 2",model="rf_bootstrap",accuracy=results_rf2[1],recall=results_rf2[2],precision=results_rf2[3],F1=results_rf2[4])
tab_rf_boot2
```

### Data 2 - 10-fold cross validation

```{r, include=FALSE}
set.seed(4867,sample.kind="Rounding")
```
```{r rf_cv_Data 2}
fit_rf_cv2<-train(class~degree_spondylolisthesis+pelvic_incidence+lumbar_lordosis_angle+sacral_slope+pelvic_radius+pelvic_tilt,
               method="rf",data=train_set1,tuneLength=5,trControl=trainControl(method="cv",number=10))
predictions_rf_cv2<-predict(fit_rf_cv2,newdata=test_set1,type="raw")
results_rf_cv2<-results_func(predictions_rf_cv2,test_set1$class)
fit_rf_cv2$results%>%arrange(desc(Accuracy))%>%head
plot(fit_rf_cv2)
```

```{r results_rf_cv_Data 2, echo=FALSE}
tab_rf_cv2<-tibble(data="Data 2",model="rf_cv",accuracy=results_rf_cv2[1],recall=results_rf_cv2[2],precision=results_rf_cv2[3],F1=results_rf_cv2[4])
tab_rf_cv2
```